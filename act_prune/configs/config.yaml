env:
  SEED: 42
  CUDA_DEVICE_ORDER: "PCI_BUS_ID" 
  OMP_NUM_THREADS: "4"
  CUDA_VISIBLE_DEVICES: "0"
  TRANSFORMERS_CACHE: /home/data/hf_cache/

paths:
  data_dir: "data/"
  log_dir: "artifacts/logs/"
  checkpoint_dir: "artifacts/checkpoints/"
  results_dir: "artifacts/results/"

model:
  path: "/home/LLM/weights/Llama-2-7b-hf"
  seqlen: 2048

benchmarks:
  ppl_wikitext2:
    run_ppl: True
  
  harness:
    run_lm_eval: True
    tasks: ["boolq"]
    num_fewshot: 0
    batch_size: 1024
    apply_chat_template: False # for instructive models run with True and False

pruning:
  sparsity_type: semi-structured_act_magnitude #semi-structured_act_magnitude
  # sparisity_ratio: null #for unstructured pruning
  prune_n: 2
  prune_m: 4
  module: layers  #layers mlp_blocks attn_blocks
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
