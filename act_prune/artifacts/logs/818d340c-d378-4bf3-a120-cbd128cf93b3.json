{
  "config": {
    "env": {
      "SEED": 42,
      "CUDA_DEVICE_ORDER": "PCI_BUS_ID",
      "OMP_NUM_THREADS": "4",
      "CUDA_VISIBLE_DEVICES": "1",
      "TRANSFORMERS_CACHE": "/home/dev/public-datasets/e.shvetsov/hugging_models"
    },
    "paths": {
      "data_dir": "data/",
      "log_dir": "artifacts/logs/",
      "checkpoint_dir": "artifacts/checkpoints/",
      "results_dir": "artifacts/results/"
    },
    "model": {
      "path": "/home/dev/public-datasets/e.shvetsov/hugging_models/gemma-3-4b-it",
      "seqlen": 2048
    },
    "benchmarks": {
      "ppl_wikitext2": {
        "run_ppl": false,
        "batch_size": 64
      },
      "harness": {
        "run_lm_eval": true,
        "tasks": [
          "arc_challenge",
          "boolq",
          "arc_easy",
          "piqa",
          "winogrande",
          "hellaswag"
        ],
        "num_fewshot": 0,
        "batch_size": 512,
        "apply_chat_template": false
      }
    },
    "pruning": {
      "sparsity_type": "semi-structured_act_magnitude",
      "transformation_type": "variance",
      "additional_transformation": "none",
      "prune_n": 8,
      "prune_m": 16,
      "module": "layers",
      "target_modules": [
        "q_proj",
        "k_proj",
        "v_proj",
        "o_proj",
        "gate_proj",
        "up_proj",
        "down_proj"
      ]
    },
    "finetuning": {
      "type": "global",
      "output_dir": "/home/LLM_activation_pruning/act_prune/artifacts/models/llama2_7b_wiki",
      "dataset_name": "Salesforce/wikitext",
      "dataset_config_name": "wikitext-2-raw-v1",
      "seed": 11,
      "max_seq_length": 2048,
      "preprocessing_num_workers": 8,
      "trust_remote_code": true,
      "num_train_epochs": 1,
      "learning_rate": 0.0001,
      "weight_decay": 0.0,
      "lr_scheduler_type": "linear",
      "warmup_ratio": 0.03,
      "per_device_train_batch_size": 1,
      "per_device_eval_batch_size": 1,
      "gradient_accumulation_steps": 16,
      "gradient_checkpointing": false,
      "save_strategy": "steps",
      "save_steps": 200,
      "report_to": null
    }
  },
  "lm_eval": {
    "arc_challenge": {
      "alias": "arc_challenge",
      "acc,none": 0.4445392491467577,
      "acc_stderr,none": 0.014521226405627075,
      "acc_norm,none": 0.45307167235494883,
      "acc_norm_stderr,none": 0.01454689205200563
    },
    "arc_easy": {
      "alias": "arc_easy",
      "acc,none": 0.7537878787878788,
      "acc_stderr,none": 0.00883990265677187,
      "acc_norm,none": 0.7184343434343434,
      "acc_norm_stderr,none": 0.009228934764519291
    },
    "boolq": {
      "alias": "boolq",
      "acc,none": 0.8110091743119267,
      "acc_stderr,none": 0.006847401355319964
    },
    "hellaswag": {
      "alias": "hellaswag",
      "acc,none": 0.49731129257120094,
      "acc_stderr,none": 0.004989709267191018,
      "acc_norm,none": 0.6700856403106951,
      "acc_norm_stderr,none": 0.004692208279690629
    },
    "piqa": {
      "alias": "piqa",
      "acc,none": 0.7279651795429815,
      "acc_stderr,none": 0.01038276378624738,
      "acc_norm,none": 0.7306855277475517,
      "acc_norm_stderr,none": 0.010350004070588758
    },
    "winogrande": {
      "alias": "winogrande",
      "acc,none": 0.6519337016574586,
      "acc_stderr,none": 0.013388004531086047
    }
  }
}