{
  "config": {
    "env": {
      "SEED": 42,
      "CUDA_DEVICE_ORDER": "PCI_BUS_ID",
      "OMP_NUM_THREADS": "4",
      "CUDA_VISIBLE_DEVICES": "1",
      "TRANSFORMERS_CACHE": "/home/dev/public-datasets/e.shvetsov/hugging_models"
    },
    "paths": {
      "data_dir": "data/",
      "log_dir": "artifacts/logs/",
      "checkpoint_dir": "artifacts/checkpoints/",
      "results_dir": "artifacts/results/"
    },
    "model": {
      "path": "/home/dev/public-datasets/e.shvetsov/hugging_models/gemma-3-4b-it",
      "seqlen": 2048
    },
    "benchmarks": {
      "ppl_wikitext2": {
        "run_ppl": false,
        "batch_size": 64
      },
      "harness": {
        "run_lm_eval": true,
        "tasks": [
          "arc_challenge",
          "boolq",
          "arc_easy",
          "piqa",
          "winogrande",
          "hellaswag"
        ],
        "num_fewshot": 0,
        "batch_size": 512,
        "apply_chat_template": false
      }
    },
    "pruning": {
      "sparsity_type": "semi-structured_act_magnitude",
      "transformation_type": "variance",
      "additional_transformation": "none",
      "prune_n": 2,
      "prune_m": 4,
      "module": "layers",
      "target_modules": [
        "q_proj",
        "k_proj",
        "v_proj",
        "o_proj",
        "gate_proj",
        "up_proj",
        "down_proj"
      ]
    },
    "finetuning": {
      "type": "global",
      "output_dir": "/home/LLM_activation_pruning/act_prune/artifacts/models/llama2_7b_wiki",
      "dataset_name": "Salesforce/wikitext",
      "dataset_config_name": "wikitext-2-raw-v1",
      "seed": 11,
      "max_seq_length": 2048,
      "preprocessing_num_workers": 8,
      "trust_remote_code": true,
      "num_train_epochs": 1,
      "learning_rate": 0.0001,
      "weight_decay": 0.0,
      "lr_scheduler_type": "linear",
      "warmup_ratio": 0.03,
      "per_device_train_batch_size": 1,
      "per_device_eval_batch_size": 1,
      "gradient_accumulation_steps": 16,
      "gradient_checkpointing": false,
      "save_strategy": "steps",
      "save_steps": 200,
      "report_to": null
    }
  },
  "lm_eval": {
    "arc_challenge": {
      "alias": "arc_challenge",
      "acc,none": 0.38054607508532423,
      "acc_stderr,none": 0.014188277712349831,
      "acc_norm,none": 0.4035836177474403,
      "acc_norm_stderr,none": 0.014337158914268448
    },
    "arc_easy": {
      "alias": "arc_easy",
      "acc,none": 0.7024410774410774,
      "acc_stderr,none": 0.009381226721815544,
      "acc_norm,none": 0.6531986531986532,
      "acc_norm_stderr,none": 0.009766326091716003
    },
    "boolq": {
      "alias": "boolq",
      "acc,none": 0.7623853211009174,
      "acc_stderr,none": 0.007444172627575039
    },
    "hellaswag": {
      "alias": "hellaswag",
      "acc,none": 0.44503087034455285,
      "acc_stderr,none": 0.004959535443170608,
      "acc_norm,none": 0.592212706632145,
      "acc_norm_stderr,none": 0.004904189257891261
    },
    "piqa": {
      "alias": "piqa",
      "acc,none": 0.7018498367791077,
      "acc_stderr,none": 0.010672964114008303,
      "acc_norm,none": 0.7154515778019587,
      "acc_norm_stderr,none": 0.01052721846413062
    },
    "winogrande": {
      "alias": "winogrande",
      "acc,none": 0.5832675611681136,
      "acc_stderr,none": 0.013856250072796316
    }
  }
}