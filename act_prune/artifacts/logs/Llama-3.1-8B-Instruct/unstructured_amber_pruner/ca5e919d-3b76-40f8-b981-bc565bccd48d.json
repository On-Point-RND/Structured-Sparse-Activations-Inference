{
  "config": {
    "env": {
      "SEED": 42,
      "CUDA_DEVICE_ORDER": "PCI_BUS_ID",
      "OMP_NUM_THREADS": "4",
      "CUDA_VISIBLE_DEVICES": "4",
      "TRANSFORMERS_CACHE": "/home/dev/public-datasets/e.shvetsov/hugging_models"
    },
    "paths": {
      "data_dir": "data/",
      "log_dir": "artifacts/logs/",
      "checkpoint_dir": "artifacts/checkpoints/",
      "results_dir": "artifacts/results/"
    },
    "model": {
      "path": "/home/data/Llama-3.1-8B-Instruct",
      "seqlen": 512
    },
    "benchmarks": {
      "ppl_wikitext2": {
        "run_ppl": false,
        "batch_size": 8
      },
      "harness": {
        "run_lm_eval": true,
        "tasks": [
          "arc_challenge",
          "boolq",
          "arc_easy",
          "piqa",
          "winogrande",
          "hellaswag"
        ],
        "num_fewshot": 0,
        "batch_size": 512,
        "apply_chat_template": false
      }
    },
    "pruning": {
      "sparsity_type": "unstructured_amber_pruner",
      "transformation_type": "none",
      "sparsity_ratio": 0.7,
      "additional_transformation": "none",
      "prune_n": 2,
      "prune_m": 4,
      "module": "layers",
      "target_modules": [
        "q_proj",
        "k_proj",
        "v_proj",
        "o_proj",
        "gate_proj",
        "up_proj",
        "down_proj"
      ]
    },
    "finetuning": {
      "type": "global",
      "output_dir": "/home/LLM_activation_pruning/act_prune/artifacts/models/llama2_7b_wiki",
      "dataset_name": "Salesforce/wikitext",
      "dataset_config_name": "wikitext-2-raw-v1",
      "seed": 11,
      "max_seq_length": 2048,
      "preprocessing_num_workers": 8,
      "trust_remote_code": true,
      "num_train_epochs": 1,
      "learning_rate": 0.0001,
      "weight_decay": 0.0,
      "lr_scheduler_type": "linear",
      "warmup_ratio": 0.03,
      "per_device_train_batch_size": 1,
      "per_device_eval_batch_size": 1,
      "gradient_accumulation_steps": 16,
      "gradient_checkpointing": false,
      "save_strategy": "steps",
      "save_steps": 200,
      "report_to": null
    }
  },
  "lm_eval": {
    "arc_challenge": {
      "alias": "arc_challenge",
      "acc,none": 0.2175767918088737,
      "acc_stderr,none": 0.012057262020972504,
      "acc_norm,none": 0.2380546075085324,
      "acc_norm_stderr,none": 0.012445770028026208
    },
    "arc_easy": {
      "alias": "arc_easy",
      "acc,none": 0.48695286195286197,
      "acc_stderr,none": 0.010256289925058445,
      "acc_norm,none": 0.4444444444444444,
      "acc_norm_stderr,none": 0.01019625483869168
    },
    "boolq": {
      "alias": "boolq",
      "acc,none": 0.5889908256880734,
      "acc_stderr,none": 0.008605429733982184
    },
    "hellaswag": {
      "alias": "hellaswag",
      "acc,none": 0.29416450906193986,
      "acc_stderr,none": 0.004547350179286277,
      "acc_norm,none": 0.335291774546903,
      "acc_norm_stderr,none": 0.0047112754081384545
    },
    "piqa": {
      "alias": "piqa",
      "acc,none": 0.602829162132753,
      "acc_stderr,none": 0.011416453840790259,
      "acc_norm,none": 0.5968443960826986,
      "acc_norm_stderr,none": 0.011444908701768744
    },
    "winogrande": {
      "alias": "winogrande",
      "acc,none": 0.5177584846093133,
      "acc_stderr,none": 0.01404361959617496
    }
  }
}